---
navigation_title: Azure
description: Set up the EDOT Cloud Forwarder for Azure to bring your Azure telemetry data to Elastic Observability.
applies_to:
  serverless:
    observability: preview
  deployment:
    ess: preview
  product:
    edot_cf_azure: preview
products:
  - id: cloud-serverless
  - id: observability
  - id: edot-cf
---

# EDOT Cloud Forwarder for Azure

{{edot-cf}} for Azure is an agentless solution that allows you to stream telemetry data from Azure services to an {{es}} cluster. {{edot-cf}} for Azure supports the following sources:

| Source | Description |
| --- | --- |
| Activity log | Logs generated by Azure Monitor |
% | Storage account metrics | Metrics generated by an Azure Storage |

Read on to learn how to set up {{edot-cf}} for Azure.

::::{note}
We are working to support other sources. Get in touch to let us know of any specific requirements that might influence our plans.
::::

## Architecture

% Add notes on architecture

## Prerequisites

::::{important}
{{edot-cf}} for Azure requires a Managed OTLP endpoint and an API key. Managed OTLP is available for {{serverless-full}} and will soon be available for {{ech}}.

For self-managed deployments, set up an EDOT Collector in [Gateway mode](elastic-agent://reference/edot-collector/config/default-config-standalone.md#gateway-mode) that ingests OTel data from the edge setup into the self-managed Elastic Stack.
::::
To collect telemetry data using {{edot-cf}} for Azure, you need:

- An Azure subscription
- Azure CLI
- Bicep extension for Azure CLI

### Azure subscription

To use {{edot-cf}} for Azure, you need an Azure subscription with permissions to create resources.

The Bicep template for {{edot-cf}} creates the following resources:

- Function App
- App Service plan
- Event Hubs Namespace with two Event Hubs (logs and metrics)
- Storage account
- Application Insights workspace

### Azure CLI

You can use the Azure CLI to deploy and manage resources required for {{edot-cf}}.

To install Azure CLI, refer to the [official documentation](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli).

### Bicep extension

{{edot-cf}} for Azure uses Bicep to define all the necessary resources and their dependencies.

After you've installed Azure CLI, install Bicep by running the following command:

```bash
az bicep install
```

## Deployment considerations

Before deploying {{edot-cf}} for Azure, take the following into consideration:

- The logs event hub supports Azure resource logs.
- Support for additional encoding extensions for logs and metrics will be added in future releases.

## Deploy EDOT CF for Azure

Follow these steps to deploy {{edot-cf}} for Azure in a resource group to send telemetry data to the {{motlp}} endpoint.

::::::{stepper}

:::::{step} Retrieve the OTLP endpoint and API key

To find out the URL of the managed OTLP endpoint and the API key for authentication, follow these steps:

::::{dropdown} Steps to retrieve the OTLP endpoint and API key

:::{include} ../_snippets/serverless-endpoint-api.md
:::

In the Bicep templates, the OTLP endpoint is set as `elasticsearchOtlpEndpoint`, and the API key is set as `elasticsearchApiKey`. 

:::{important}
Trim the API key from `Authorization=ApiKey MYKEYVALUE...` to just `MYKEYVALUE...` before using it as the argument to the `elasticsearchApiKey` parameter.
:::
::::
:::::

:::::{step} Set the environment variables
Define the following environment variables:

```sh
export AZURE_LOCATION="<your_region>"
export RESOURCE_GROUP="<group_name>"
export ELASTICSEARCH_OTLP_ENDPOINT="<your_otlp_endpoint>"
export ELASTICSEARCH_API_KEY="<your_api_key>"
```
:::::

:::::{step} Create the resource group
Create the resource group that hosts all the resources for {{edot-cf}} for Azure.

```sh
$ az group create --name $RESOURCE_GROUP --location $AZURE_LOCATION
{
  "id": "/subscriptions/<subscription_id>/resourceGroups/<group_name>",
  "location": "<your_region>",
  "managedBy": null,
  "name": "<group_name>",
  "properties": {
    "provisioningState": "Succeeded"
  },
  "tags": null,
  "type": "Microsoft.Resources/resourceGroups"
}
```
:::::

:::::{step} Download the Bicep template
Download the Bicep template to deploy {{edot-cf}} for Azure at the following URL: https://ela.st/edot-cf-azure-template
:::::

:::::{step} Deploy the Bicep template
Deploy the Bicep template using the following command:

```sh
az deployment group create \
    --resource-group ${RESOURCE_GROUP} \
    --template-file ecf.bicep \
    --parameters \
        elasticsearchOtlpEndpoint=$ELASTICSEARCH_OTLP_ENDPOINT \
        elasticsearchApiKey=$ELASTICSEARCH_API_KEY \
        logsDecoder=ds \ <1>
        metricsDecoder=dcr \ <2>
        eventHubPartitionCount=8 \
        eventHubMessageRetentionInDays=1 \
```

1. To collect Activity logs from a diagnostic settings, set `logsDecoder` to `ds` (diagnostic settings).
2. To collect Storage Account metrics from a Data Collection Rule, set `metricsDecoder` to `dcr` (data collection rules).

For a complete list of parameters, refer to [Configure the template](#configure-the-template).
:::::

:::::{step} Collect telemetry data
Follow these instructions to collect telemetry data depending on your use case.

::::{tab-set}

:::{tab-item} Activity logs
Create a diagnostic setting to collect Activity logs from an Azure subscription.

1. In the Azure portal, open **Subscriptions** from the search bar.
2. Select the Azure subscription from which you want to collect Activity logs.
3. Go to **Activity log** → **Export Activity Logs** → **Add diagnostic setting**.
  - In **Diagnostic setting name**, enter a name for the diagnostic setting.
  - Select all categories in **Logs > Administrative**.
  - In **Destination details**, select **Stream to an event hub**.
  - In **Event hub namespace**, select the namespace created by the EDOT Cloud Forwarder (ECF) for Azure.
  - In **Event hub name (optional)**, select the `logs` event hub created by the EDOT Cloud Forwarder (ECF) for Azure.
4. Select **Save** to create the diagnostic setting.
5. After a few minutes, the diagnostic setting starts streaming the Activity logs to the `logs` event hub.
6. Go to **Discover** in your {{ecloud}} deployment or Serverless project, and select the `logs-*` data view.
7. Filter the docs by `data_stream.dataset`, to browse the Activity logs streamed to {{es}}.
:::

<!--
:::{tab-item} Storage Account metrics
Create a Data Collection rule to collect metrics from Storage Account metrics.

1. In the Azure portal, open **Data collection rules** from the search bar.
2. Select **Create**.
3. In **Basics**:
  - Turn on the platform metrics by selecting the section labeled *To create a Data Collection Rule that collects platform metrics, click here*.
  - Enter a **Name** for the Data Collection Rule.
  - Select or create a new **Resource group**. You can use the same resource group created by the {{edot-cf}} for Azure.
  - In **Identity**, turn on **Enable Managed Identity** and select **System assigned**. This streams the metrics to the Event Hub.
4. In **Resources**:
  - Select **Add resources**, then select the Storage Account from which you want to collect metrics.
5. In **Collect and deliver**:
  - Select **Add new dataflow**.
  - From **Data source type**, select **Platform metrics**.
  - From **Resource types**, select the types of resources from which you want to collect metrics.
  - Select **Destination**.
  - From **Destination type**, select **Event hub**, and then select the `metrics` Event Hub created by the {{edot-cf}} for Azure.
  - Go to **Review and create** and select **Create**.
6. After some time, the Data Collection Rule start streaming the Storage Account metrics to the `metrics` event hub.
7. Go to **Discover** in your {{ecloud}} deployment or Serverless project, and select the `metrics-*` data view.
8. Filter the docs by `data_stream.dataset`, to browse the Storage Account metrics streamed to {{es}}.

:::{note}
The Data Collection rule can take up to 30 minutes, or more, before starting to stream metrics to the Event Hub.
:::
:::
-->
::::
:::::
::::::

## Configure the template

{{edot-cf}} for Azure uses a Bicep template to deploy the EDOT CF.

The following parameters are available in the Bicep template:

| Parameter                        | Default | Description                                                          | Available options                                                      |
| -------------------------------- | ------- | -------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| `elasticsearchOtlpEndpoint`      |         | OTLP service endpoint.                                               |                                                                        |
| `elasticsearchApiKey`            |         | Elasticsearch API key.                                               |                                                                        |
| `logsDecoder`                    | `ds`    | Decoder to decode the logs.                                          | `ds` (diagnostic settings)                                             |
| `metricsDecoder`                 | `ds`    | Decoder to decode the metrics.                                       | `ds` (diagnostic settings) and `dcr` (Data Collection Rules)           |
| `eventHubPartitionCount`         | `4`     | Number of partition in the event hubs.                               |                                                                        |
| `eventHubMessageRetentionInDays` | `1`     | Number of days for the event hub data retention.                     |                                                                        |
% | `version`                        | `0.6.0` | EDOT Cloud Forwarder (ECF) for Azure Tech Preview version to deploy. | The `infra/ecf.bicep` contains the latest version available.           |

## Resource group resources

The Bicep template creates a number of resources to process logs from a specific log source.

This is the list of resources created by the Bicep template.

| Resource name         | Type                                      | Description                                                                                              |
| --------------------- | ----------------------------------------- | -------------------------------------------------------------------------------------------------------- |
| `eventHubNamespace`   | `Microsoft.EventHub/namespaces`           | Event Hubs namespace to host the event hubs to stream logs and metrics.                                  |
| `logsEventHub`        | `Microsoft.EventHub/namespaces/eventhubs` | Event hub for the logs.                                                                                  |
| `metricsEventHub`     | `Microsoft.EventHub/namespaces/eventhubs` | Event hub for the metrics.                                                                               |
| `storageAccount`      | `Microsoft.Storage/storageAccounts`       | Storage Account container to store the Event Hubs trigger checkpoint information and the failed messages. |
| `hostingPlan`         | `Microsoft.Web/serverfarms`               | Hosting plan that runs the function app.                                                                 |
| `functionApp`         | `Microsoft.Web/sites`                     | The function app that runs the EDOT Collector.                                                           |
| `applicationInsights` | `Microsoft.Insights/components`           | Application Insights instance to monitor the application.                                                |

Note the following:

- The `eventHubNamespace` hosts the two event hubs responsible for receiving logs and metrics from Azure services. 
- The `storageAccount` stores the checkpoint information for the Event Hub triggers, and it also hosts the failed logs and metrics in the `logs-error-container` and `metrics-error-container` containers. 
- The `functionApp` is the core component responsible for running the OTel collector inside the Azure Function. 

## Remove the resource group

If you no longer need the resources and want to remove them, use the following command:

```sh
az group delete --name $RESOURCE_GROUP
```

This removes all the resources in the resource group.

:::{warning}
If you remove the resource group, data that's still unprocessed will be lost.
:::
